{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import networkx as nx\n",
    "import tqdm\n",
    "from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\n",
    "from fairseq.models.text_to_speech.hub_interface import TTSHubInterface\n",
    "import IPython.display as ipd\n",
    "\n",
    "webNLG_dataset = load_dataset(\"web_nlg\", \"webnlg_challenge_2017\")\n",
    "\n",
    "models, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n",
    "    \"facebook/fastspeech2-en-ljspeech\",\n",
    "    arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False, \"output-sample-rate\": 16000}\n",
    ")\n",
    "\n",
    "task.sr = 22050\n",
    "model = models[0]\n",
    "TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\n",
    "generator = task.build_generator(models, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6940 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m each_wav_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m each_text \u001b[39min\u001b[39;00m each[\u001b[39m\"\u001b[39m\u001b[39mlex\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     each_wav_list\u001b[39m.\u001b[39mappend(generate_audio_content(each_text))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m wav_list\u001b[39m.\u001b[39mappend(each_wav_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m G \u001b[39m=\u001b[39m generate_graph_for_tripple_set(each[\u001b[39m\"\u001b[39m\u001b[39mmodified_triple_sets\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmtriple_set\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32m/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_audio_content\u001b[39m(text):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     sample \u001b[39m=\u001b[39m TTSHubInterface\u001b[39m.\u001b[39mget_model_input(task, text)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     wav, rate \u001b[39m=\u001b[39m TTSHubInterface\u001b[39m.\u001b[39;49mget_prediction(task, model, generator, sample)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sachethchandramouli/Documents/GitHub/CS546-CLEO/data_conversion_pipeline.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m wav\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/models/text_to_speech/hub_interface.py:132\u001b[0m, in \u001b[0;36mTTSHubInterface.get_prediction\u001b[0;34m(cls, task, model, generator, sample)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_prediction\u001b[39m(\u001b[39mcls\u001b[39m, task, model, generator, sample) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, \u001b[39mint\u001b[39m]:\n\u001b[0;32m--> 132\u001b[0m     prediction \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49mgenerate(model, sample)\n\u001b[1;32m    133\u001b[0m     \u001b[39mreturn\u001b[39;00m prediction[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mwaveform\u001b[39m\u001b[39m\"\u001b[39m], task\u001b[39m.\u001b[39msr\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/speech_generator.py:139\u001b[0m, in \u001b[0;36mNonAutoregressiveSpeechGenerator.generate\u001b[0;34m(self, model, sample, has_targ, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m out_dim \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencoder\u001b[39m.\u001b[39mout_dim\n\u001b[1;32m    137\u001b[0m raw_dim \u001b[39m=\u001b[39m out_dim \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m n_frames_per_step\n\u001b[0;32m--> 139\u001b[0m feat, feat_post, out_lens, log_dur_out, _, _ \u001b[39m=\u001b[39m model(\n\u001b[1;32m    140\u001b[0m     src_tokens\u001b[39m=\u001b[39;49msample[\u001b[39m\"\u001b[39;49m\u001b[39mnet_input\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39msrc_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    141\u001b[0m     src_lengths\u001b[39m=\u001b[39;49msample[\u001b[39m\"\u001b[39;49m\u001b[39mnet_input\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39msrc_lengths\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    142\u001b[0m     prev_output_tokens\u001b[39m=\u001b[39;49msample[\u001b[39m\"\u001b[39;49m\u001b[39mnet_input\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mprev_output_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    143\u001b[0m     incremental_state\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    144\u001b[0m     target_lengths\u001b[39m=\u001b[39;49msample[\u001b[39m\"\u001b[39;49m\u001b[39mtarget_lengths\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    145\u001b[0m     speaker\u001b[39m=\u001b[39;49msample[\u001b[39m\"\u001b[39;49m\u001b[39mspeaker\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m feat_post \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     feat \u001b[39m=\u001b[39m feat_post\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/models/fairseq_model.py:559\u001b[0m, in \u001b[0;36mFairseqEncoderModel.forward\u001b[0;34m(self, src_tokens, src_lengths, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src_tokens, src_lengths, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[39m    Run the forward pass for a encoder-only model.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m        the encoder's output, typically of shape `(batch, src_len, features)`\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(src_tokens, src_lengths, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/models/text_to_speech/fastspeech2.py:311\u001b[0m, in \u001b[0;36mFastSpeech2Encoder.forward\u001b[0;34m(self, src_tokens, src_lengths, speaker, durations, pitches, energies, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_speaker(speaker)\u001b[39m.\u001b[39mexpand(bsz, seq_len, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    309\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspk_emb_proj(torch\u001b[39m.\u001b[39mcat([x, emb], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m--> 311\u001b[0m x, out_lens, log_dur_out, pitch_out, energy_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_adaptor(\n\u001b[1;32m    312\u001b[0m     x, enc_padding_mask, durations, pitches, energies\n\u001b[1;32m    313\u001b[0m )\n\u001b[1;32m    315\u001b[0m dec_padding_mask \u001b[39m=\u001b[39m lengths_to_padding_mask(out_lens)\n\u001b[1;32m    316\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdec_pos_emb_alpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions(dec_padding_mask)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/models/text_to_speech/fastspeech2.py:207\u001b[0m, in \u001b[0;36mVarianceAdaptor.forward\u001b[0;34m(self, x, padding_mask, durations, pitches, energies, d_factor, p_factor, e_factor)\u001b[0m\n\u001b[1;32m    202\u001b[0m dur_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp(\n\u001b[1;32m    203\u001b[0m     torch\u001b[39m.\u001b[39mround((torch\u001b[39m.\u001b[39mexp(log_dur_out) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m d_factor)\u001b[39m.\u001b[39mlong(), \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    204\u001b[0m )\n\u001b[1;32m    205\u001b[0m dur_out\u001b[39m.\u001b[39mmasked_fill_(padding_mask, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m pitch_out, pitch_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_pitch_emb(x, pitches, p_factor)\n\u001b[1;32m    208\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m pitch_emb\n\u001b[1;32m    209\u001b[0m energy_out, energy_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_energy_emb(x, energies, e_factor)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/models/text_to_speech/fastspeech2.py:170\u001b[0m, in \u001b[0;36mVarianceAdaptor.get_pitch_emb\u001b[0;34m(self, x, tgt, factor)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pitch_emb\u001b[39m(\u001b[39mself\u001b[39m, x, tgt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, factor\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m):\n\u001b[0;32m--> 170\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpitch_predictor(x)\n\u001b[1;32m    171\u001b[0m     bins \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpitch_bins\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m tgt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/fairseq/models/text_to_speech/fastspeech2.py:150\u001b[0m, in \u001b[0;36mVariancePredictor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1(x))\n\u001b[1;32m    149\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 150\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln2(x))\n\u001b[1;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj(x)\u001b[39m.\u001b[39msqueeze(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/modules/normalization.py:196\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlayer_norm(\n\u001b[1;32m    197\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cleo/lib/python3.10/site-packages/torch/nn/functional.py:2543\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight, bias):\n\u001b[1;32m   2540\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2541\u001b[0m         layer_norm, (\u001b[39minput\u001b[39m, weight, bias), \u001b[39minput\u001b[39m, normalized_shape, weight\u001b[39m=\u001b[39mweight, bias\u001b[39m=\u001b[39mbias, eps\u001b[39m=\u001b[39meps\n\u001b[1;32m   2542\u001b[0m     )\n\u001b[0;32m-> 2543\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mlayer_norm(\u001b[39minput\u001b[39;49m, normalized_shape, weight, bias, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Converting tripple set to a graph\n",
    "def generate_graph_for_tripple_set(tripple_set):\n",
    "    G = nx.Graph()\n",
    "    for tripple in tripple_set:\n",
    "        tripple = tripple.split(\" | \")\n",
    "        ## check if node is in G\n",
    "        if tripple[0] not in G.nodes:\n",
    "            G.add_node(tripple[0])\n",
    "        if tripple[1] not in G.nodes:\n",
    "            G.add_node(tripple[1])\n",
    "        if tripple[2] not in G.nodes:\n",
    "            G.add_node(tripple[2])\n",
    "        ## Add edge between nodes\n",
    "        G.add_edge(tripple[0], tripple[1])\n",
    "        G.add_edge(tripple[1], tripple[2])\n",
    "    return nx.cytoscape_data(G)\n",
    "\n",
    "## Printing function for each\n",
    "def print_details(idx):\n",
    "    print(\"EID: \", eid_list[idx])\n",
    "    for idx, text in enumerate(text_list[idx]):\n",
    "        print(f\"Option {idx}: {text}\\n\")\n",
    "    \n",
    "    print(\"Graph Visual:\")\n",
    "    nx.draw(nx.cytoscape_graph(graph_list[idx]),with_labels=True, font_size=8)\n",
    "    \n",
    "def generate_audio_content(text):\n",
    "    sample = TTSHubInterface.get_model_input(task, text)\n",
    "    wav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)\n",
    "    return wav\n",
    "\n",
    "G = generate_graph_for_tripple_set(webNLG_dataset[\"train\"][0][\"modified_triple_sets\"][\"mtriple_set\"][0])\n",
    "\n",
    "## Iterate through all the triple sets and generate graphs\n",
    "eid_list = []\n",
    "graph_list = []\n",
    "text_list = []\n",
    "wav_list = []\n",
    "\n",
    "for each in tqdm.tqdm(webNLG_dataset[\"train\"]):\n",
    "    eid_list.append(each[\"eid\"])\n",
    "    text_list.append(each[\"lex\"][\"text\"])\n",
    "    ## Create the WAV file:\n",
    "    each_wav_list = []\n",
    "    for each_text in each[\"lex\"][\"text\"]:\n",
    "        each_wav_list.append(generate_audio_content(each_text))\n",
    "    wav_list.append(each_wav_list)\n",
    "    G = generate_graph_for_tripple_set(each[\"modified_triple_sets\"][\"mtriple_set\"][0])\n",
    "    graph_list.append(G)\n",
    "\n",
    "## Save the data\n",
    "import pickle\n",
    "with open(\"webNLG_data.pickle\", \"wb\") as f:\n",
    "    pickle.dump({\"eid_list\": eid_list, \"graph_list\": graph_list, \"text_list\": text_list, \"wav_list\": wav_list}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = generate_audio_content(text_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0002, -0.0012, -0.0012,  ..., -0.0013, -0.0011, -0.0009])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
